---
layout: episode
permalink: /stops/2/
type: stop
section_title: Museum of Forbidden Technologies
title: Dark Sousveillance
page_rank: 2
stop_id: 2
audio_file: 2.m4a
hero_images:
---
## Panel Text
Everything we do is focused on ensuring that we provide a high-quality experience for all our customers, who are ethnically diverse and live and work around the world. That's why when issues surface, we take them seriously and work hard to understand the root causes. Some of you may have seen or heard of a YouTube video in which the facial-tracking software didn't work for a customer. We thank Desi, and the people who have seen and commented on his video, for bringing this subject to our attention.

We are working with our partners to learn more. The technology we use is built on standard algorithms that measure the difference in intensity of contrast between the eyes and the upper cheek and nose. We believe that the camera might have difficulty “seeing” contrast in conditions where there is insufficient foreground lighting.

*Tony Welch [Frosty], “Customer Feedback is Important to Us.”, The Next Bench,  December 4, 2009*

## Transcript
In December 2009, coworkers Desi (a black man) and Wanda (a white woman) tested out Hewlett-Packard's face-tracking feature. When Wanda appears on screen, the camera moves; when Desi appears, the camera freezes and does nothing.

It would be an oversight to not acknowledge the racialized histories of these technologies. Whose bodies and freedoms are the most controlled and curtailed? 2Sociologist Simone Browne traces surveillance technologies to colonial logics of anti-Blackness, capital, governance, property and violence. From the transatlantic slave trade to contemporary biometric information technologies, lantern laws of nineteenth-century New York to Hewlett Packard’s face-tracking camera failure referenced here in the label, racializing surveillance involves both hypervisibility and invisibility.

Browne and colleagues challenge the repressions through the concept of sousveillance. If surveillance is the authority watching the individual, writing technology to ascribe blackness, sousveillance is the individual looking back at the authority, to change that perception. Dark sousveillance shines light on institutions to contend with black surveillance, seeing each other through a lens of care, rather than oppression.

Browne points to spirituals detailing escape routes and abolitionist bills. What do these histories and racial classifications continue to do as the technology defines blackness? Browne’s definition points to the hypervisibility of Black deaths on livestreaming applications, mobile apps like CopWatch and CopBlock, and coalitions like Stop LAPD Lying or #BlackLivesMatter which engage sousveillance with agents of authority to bring to light these racialized efforts of surveillance.

Browne also notes that in cases like the HP scandal, blackness can also make one invisible from surveillance. What might those efforts look like today, to render one’s self out of sight from surveillance technology through race?

### Definition
**dark sousveillance**: a site of critique, as it speaks to black epistemologies of contending with antiblack surveillance, where the tools of social control...were appropriated, co-opted, repurposed, and challenged in order to facilitate survival and escape. (Browne 2015)

### Resources
- Browne, Simone. *Dark Matters: On the Surveillance of Blackness.* Duke University Press (2015).
- [Copwatch](https://www.copwatch.org.au/)
- [CopBlock](https://www.copblock.org/apps/)
- [Stop LAP Spying Coalition](https://stoplapdspying.org/)
- "Simone Browne | Dark Sousveillance Race, Surveillance and Resistance." CUNY Graduate Center, 9 December 2013. [Link here](https://www.youtube.com/watch?v=IsMFdiLsqbg).
- [HP computers are racist.](https://www.youtube.com/watch?v=t4DT3tQqgRM)
